{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea: Sistemas Lineales, PCA y Fourier\n",
    "\n",
    "El siguiente es un problema que puede dar resultados interesantes o no, lo importante es seguir adelante con el procedimiento independientemente de si obtienen o no un buen resultado. La razón es simple, vamos a intentar hacer un experimento: Reconocer dígitos escritos a \"mano\". Este es un problema tradicional para aprender Machine Learning. Vamos a tomar la base de datos de imágenes digitalizadas de números de [MNIST](http://yann.lecun.com/exdb/mnist/). Ejecutar la siguiente celda para cargar la base de datos de números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading training set\n",
      "Downloading training labels\n",
      "Downloading test set\n",
      "Downloading test labels\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import sys; import os\n",
    "\n",
    "import numpy as np\n",
    "np.seterr(all='raise')\n",
    "np.random.seed(13)\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# mpl.rc('text', usetex=True)\n",
    "%matplotlib inline\n",
    "\n",
    "import pylab\n",
    "import scipy as sp\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import urllib.request\n",
    "import gzip\n",
    "import struct\n",
    "\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "DATADIR='data'\n",
    "\n",
    "print('Downloading training set')\n",
    "fname = DATADIR+'/train.gz'\n",
    "if not (os.path.exists(fname) and os.path.isfile(fname)):\n",
    "    urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',fname)\n",
    "print('Downloading training labels')\n",
    "fname = DATADIR+'/train-labels.gz'\n",
    "if not (os.path.exists(fname) and os.path.isfile(fname)):\n",
    "    urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',fname)\n",
    "print('Downloading test set')\n",
    "fname = DATADIR+'/test.gz'\n",
    "if not (os.path.exists(fname) and os.path.isfile(fname)):\n",
    "    urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',fname)\n",
    "print('Downloading test labels')\n",
    "fname = DATADIR+'/test-labels.gz'\n",
    "if not (os.path.exists(fname) and os.path.isfile(fname)):\n",
    "    urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',fname)\n",
    "print('Done!')\n",
    "\n",
    "# Esta función es una adaptación de la clase MNIST de la librería \"python-mnist\"\n",
    "# que la encuentran en el siguiente vínculo: https://github.com/sorki/python-mnist\n",
    "def loadSet(s='train'):\n",
    "    from array import array\n",
    "    with gzip.open('data/'+s+'-labels.gz', 'rb') as file:\n",
    "        magic, size = struct.unpack(\">II\", file.read(8))\n",
    "        if magic != 2049:\n",
    "            raise ValueError('Magic number mismatch, expected 2049,'\n",
    "                             'got {}'.format(magic))\n",
    "        labels = np.array(array(\"B\", file.read()))\n",
    "\n",
    "    with gzip.open('data/'+s+'.gz', 'rb') as file:\n",
    "        magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "        if magic != 2051:\n",
    "            raise ValueError('Magic number mismatch, expected 2051,'\n",
    "                             'got {}'.format(magic))\n",
    "        image_data = array(\"B\", file.read())\n",
    "        images = np.zeros((size,rows*cols),dtype=np.uint8)\n",
    "        for i in range(size):\n",
    "            images[i][:] = image_data[i * rows * cols:(i + 1) * rows * cols]\n",
    "    del array\n",
    "    del sys.modules['array']\n",
    "    return {\n",
    "        'data':images,'target':labels,\n",
    "        'target_names': np.unique(labels),\n",
    "        # 'images': np.reshape(images,(size,rows,cols))\n",
    "    }\n",
    "MNIST_train = loadSet('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora inspeccionemos el objeto de datos:\n",
    "Es un dictionario con cuatro llaves: `data`, `target`, `target_names` e `images`. La terminología puede ser complicada pero con el ejemplo todo será claro.\n",
    "\n",
    "* `data` contiene los datos de las $60\\times10^3$ imágenes en formato de vector unidimensional de $28\\times28=784$ correspondiente a la **densidad** de color negro (un número entre 0-*blanco* y 255-*negro*) de cada pixel de las imágenes de $28\\times28$. Es decir, cada fila de data contiene un vector que corresponde a esa densidad de color pixel a pixel de las imágenes digitalizadas de números escritos a mano.\n",
    "* `target` contiene las etiquetas correspondientes a las $60\\times10^3$ imágenes.\n",
    "* `target_names` contiene el conjunto de todas las etiquetas posibles. Ahora como son números, esta etiqueta es naturalmente el conjunto $\\{0,1,2,3,4,5,6,7,8,9\\}$\n",
    "<!-- * `images` contiene la misma información que `data` en formato matricial de $28\\times28$. -->\n",
    "\n",
    "El siguiente ejemplo me muestra el dato número $13$ de la serie. **Nota:** fíjense que para poderlo graficar usamos `plt.gray()` ajusta el gráfico en escala de grises, `plt.matshow` de Matplotlib que me muestra matrices, y, lo más importante, hacemos un <u>reshape</u> en el que el vector unidimensional de $784$ lo convertimos en una matriz de $28\\times28$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El elemento 13 del conjunto de datos corresponde al número: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "print(\"El elemento 13 del conjunto de datos corresponde al número:\",MNIST_train['target'][13])\n",
    "plt.matshow(np.reshape(MNIST_train['data'][13],(28,28)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Cuál es el ejercicio? Clasificar correctamente los números usando la misma regresión lineal.\n",
    "\n",
    "¿Tiene sentido esto? Bueno, vamos a descubrir. Esa es la escencia de la Ciencia, la exploración.\n",
    "\n",
    "El conjunto de datos que deberá clasificar correctamente es el correspondiente al último número de su código. Por ejemplo, el mío siendo $200810693$ sería el conjunto del número $3$; defina una variable global llamada `digit` con este valor. Es decir, quiero encontrar un algoritmo que me identifique de las $60k$ imágenes aquellas que sean el número $3$. Por simplicidad, puedo asumir que cualquier imagen que corresponda a un número diferente del $3$ es como si fuera $0$ y la que corresponda al número $3$ es como si fuera $1$. Lo que quiere decir que tenemos que <u>redefinir</u> `target`. *E.g.* si $\\mathbf{target}=\\{0,5,3,4,3,8,7,2,1,\\dots\\}$ entonces $\\mathbf{target\\_new}=\\{0,0,1,0,1,0,0,0,0,\\dots\\}$. A continuación, defina en el dictionario `MNIST_train` una nueva llave `target_new` que contenga estas nuevas etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit=3\n",
    "n_dig= np.sum(np.sum(MNIST_train['target'] == digit))\n",
    "n_ft=MNIST_train['data'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "redefTarget = lambda x,y: 1 if x==y else 0\n",
    "redefTarget = np.vectorize(redefTarget,excluded=(1,))\n",
    "MNIST_train['target_new'] = redefTarget(MNIST_train['target'],digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificamos\n",
      "\t¿cuántos con 3? 6131\n",
      "\t¿la suma de 'target_new'? 6131\n"
     ]
    }
   ],
   "source": [
    "print(\"Verificamos\")\n",
    "print(\"\\t¿cuántos con %d? %d\"%(digit,n_dig))\n",
    "print(\"\\t¿la suma de 'target_new'? %d\"%np.sum(MNIST_train['target_new']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La siguiente parte es intentar hacer un *ajuste no-lineal* ligeramente <u>parecido</u> al ejemplo lineal\n",
    "El ajuste lineal que vamos a hacer tiene que ver con el peso que va a tener el conjunto de datos con mi `digito` seleccionado sobre el total de datos para el *ajuste* (entrenamiento). Si sólo el $\\sim10\\%$ de los datos corresponde a mi dígito, la regresión con `target_new` podría ajustarse tranquilamente sólo a los ceros y tener una precisión del $\\sim90\\%$, algo que a priori diríamos que está genial, pero si nos damos cuenta el ajuste que tendríamos sería incapaz de reconocer mi `digito` de los demás. Por ende, es necesario saber cuantos elementos del **set** de entrenamiento tengo iguales a mi dígito y elegir el mismo número de elementos no iguales a mi dígito para crear el **set completo** de entrenamiento; llamemos a este número $n_{dig}$. Por otra parte, vamos a denotar $n_{ft}$ el número de parámetros del sistema; para este caso tengamos presente que són $784$ el mismo número que pixeles de la imagen. Luego, para el ajuste, debo seleccionar el mismo número de elementos complementarios. Es decir, que si mi `digito` es $3$ debo escoger $6131$ datos cuyo dígito sea cualquiera menos el $3$ ya que el set tiene $6131$ elementos del $3$. A continuación, cree dos matrices y el vector \"respuesta\": una que tenga los datos de los aciertos a su dígito y otra que tenga los datos de desaciertos (recomiendo que los elija al azar usando, por ejemplo, la función `np.random.choice`). Una vez haya hecho esto concaténelos usando `np.concatenate` y cree las matrices `A` y `Y` del **set completo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora realice el ajuste encontrando $\\mathbb{X}_{opt}$\n",
    "\n",
    "El ajuste *lineal* que vamos a hacer no es evidente ya que la función más adecuada para este sistema es la sigmoidal. Recordemos,\n",
    "$$\\hat{y}_j=\\frac{1}{1+e^{-\\mathbb{A}^{(j)}\\cdot\\mathbb{X}_{opt}}},$$\n",
    "donde $j$ es el índice del dato de los $2n_{dig}$ posibles; es decir, $\\mathbb{A}^{(j)}$ es la $j-\\text{ésima}$ fila de la matriz $\\mathbb{A}$ y $\\hat{y}_j$ es la predicción del modelo respecto a si la imagen es un $3$ u otro número diferente cuando $\\hat{y}_j\\to1$ o $\\hat{y}_j\\to0$ respectivamente.\n",
    "<!-- $\\mathbb{A}\\mathbb{X}_{opt} = \\hat{\\mathbb{Y}}$ tal que $L(\\hat{\\mathbb{Y}},\\mathbb{Y})=\\frac{1}{4n_{dig}}\\Vert\\hat{\\mathbb{Y}}-\\mathbb{Y}\\Vert^2$ sea lo mínimo posible -->\n",
    "Ahora la pregunta es ¿cuál va a ser la función de costo? En este caso, se utiliza una función muy especial llamada la entropía cruzada (por sus siglas en inglés *crossed entropy*) definida así,\n",
    "$$L(\\hat{\\mathbb{Y}},\\mathbb{Y})=-\\frac{1}{2n_{dig}}\\sum_{j=1}^{2n_{dig}}\\left[y_j\\log\\hat{y}_j+(1-y_j)\\log(1-\\hat{y}_j)\\right].$$\n",
    "El signo negativo es porque $0<\\hat{y}_j<1$ con lo cual $\\log\\hat{y}_j<0$ y $\\log(1-\\hat{y}_j)<0$ pero tienden a cero cuando los ajustes son perfectos. Una observación, noten como esos dos términos están convenientemente definidos: $y_j$ es o cero o $1$ con lo cual, dependiendo del caso, sobrevive sólo uno de los términos. Esta definición es muy conveniente y se parece a la definición de la entropía de Shannon. ¡Una cosa interesante de esta definición es el mínimo! Está garantizada que esta es una función convexa y tiene un mínimo. ¿Cuál es el gradiente? (es importante que ustedes lo demuestren por su cuenta)\n",
    "$$\\vec{\\nabla}_{\\mathbb{X}_{opt}}L=\\frac{1}{2n_{dig}}\\mathbb{A}^\\text{T}\\cdot(\\hat{\\mathbb{Y}}-\\mathbb{Y}),$$\n",
    "con $\\hat{\\mathbb{Y}}$ y $\\mathbb{Y}$ los vectores columna de las predicciones y las etiquetas reales.\n",
    "\n",
    "Escriba las funciones de costo y su jacobiano (derivada) y resuelva usando SciPy `minimize` (recomiendo usar los siguientes parámetros para la función: `method='L-BFGS-B', tol=1e-8`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X,A):\n",
    "    # Escriba la funcion sigmoidal\n",
    "    return \n",
    "def L(X,A,Y):\n",
    "    # Escriba la funcion de costo\n",
    "    return \n",
    "def Jac(X,A,Y):\n",
    "    # Escriba el jacobiano de la funcion de costo\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimice para encontrar X_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Problemas? ¡Hay muchos ceros! ¿Qué hacemos? PCA\n",
    "\n",
    "El problema que se presenta es debido a que todas las $784$ variables (correspondientes a los pixeles que serían los features) no son necesarios y se representa con que la matriz $\\mathbb{A}^{\\text{T}}\\mathbb{A}$ es invertible (**¡ensáyenlo por favor!**). La solución está a la vista con un Análisis de Componentes Principales. Luego, realice el respectivo análisis de la matriz $\\mathbb{A}$ y escoja $n_{pca}=2, 3, 10, 100, 300$ componentes y haga la optimización calculando así los coeficientes para los componentes principales que me ayudan a clasificar si una imagen corresponde a un $3$ u otro número. Ojo, en mi caso tengo que clasificar las imágenes con el número $3$. Tengan presente que aquí el problema cambia ligeramente,\n",
    "$$\\hat{y}_j=\\frac{1}{1+e^{-\\mathbb{A}_{pca}^{(j)}\\cdot\\tilde{\\mathbb{X}}_{opt}}},$$\n",
    "siendo $\\tilde{\\mathbb{X}}_{opt}$ los pesos que optimizan la predicción de nuestro algoritmo para los $n_{pca}$ componentes principales.\n",
    "\n",
    "Por simplicidad utilice la librería `sklearn` como lo hicieron en el laboratorio. Por simplicidad, llame a la nueva matriz $\\mathbb{A}_{pca}$. Les recomiendo revisar la proporción de varianza acumulada con el número de componentes mediante la propiedad de la clase PCA de `sklearn` llamada `explained_variance_ratio_` que les permitirá hacer una gráfica. Pueden revisar más en detalle en el siguiente [vínculo](https://mscipio.github.io/post/pca-tutorial-using-scikit-learn-python-module/). Hay una librería que desarrollaron para complementar el paquete de funciones gráficas de `sklearn` y dentro de ellas aparecen dos gráficas que me gustaría que ensayaran como se verían con nuestros datos. La librería se llama [SciKit-Plot](https://scikit-plot.readthedocs.io/en/stable/decomposition.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPCA(X):\n",
    "    # Escriba una función que grafica la varianza relativa acumulada\n",
    "    return \n",
    "#plotPCA(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encuentra A_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimice encontrando Xtilde_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora que ustedes encontraron $\\tilde{\\mathbb{X}}_{opt}$ calculemos la precisión de nuestro algoritmo\n",
    "\n",
    "Para hacerlo debemos calcular $\\hat{\\mathbb{Y}}$ pero tenga presente que este es un número entre $0$ y $1$. Sin embargo, para comparar con los datos que tenemos debemos redondear. La regla es que si el valor es inferior a $0.5$ entonces redondeo a cero y superior redondeo a $1$. Al realizar eso, podemos comparar para sacar la precisión.\n",
    "\n",
    "> Para que puedan probar si están haciendo bien el cálculo, cuando ustedes escogen <u>sólo</u> $2$ componentes la precisión es superior a $\\sim83\\%$. ¡Imagínense el **poder** que tiene una simple regresión!\n",
    "\n",
    "Adicionalmente, deben graficar la primera componente vs la segunda componente para los diferentes grupos de etiquetas. Recomiendo usar `scatterplot` de Seaborn. Les dejo a continuación unas gráficas bonitas, que es lo que quisiera que ver, para que vean el comportamiento de los grupos.\n",
    "\n",
    "![3 vs 0](plot-3-0.png)\n",
    "![3 vs 1](plot-3-1.png)\n",
    "![3 vs 2](plot-3-2.png)\n",
    "![3 vs 4](plot-3-4.png)\n",
    "![3 vs 5](plot-3-5.png)\n",
    "![3 vs 6](plot-3-6.png)\n",
    "![3 vs 7](plot-3-7.png)\n",
    "![3 vs 8](plot-3-8.png)\n",
    "![3 vs 9](plot-3-9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acá les dejo una función que les convierte Y_hat en etiquetas\n",
    "labeler = lambda x,y:0 if x<y else 1\n",
    "labeler = np.vectorize(labeler,excluded=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar la precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¡Grafique!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalmente, cómo me gusta complicar las cosas...\n",
    "\n",
    "Cómo se podrán dar cuenta, para poder identificar un número de otro, es necesario tomar diferencias en patrones y qué mejor sistema de identificación de patrones que... Fourier. Asumiendo que el periodo $T=783$, calculen los coeficientes de la representación en serie de Fourier para cada una de las imágenes. ¿Cuántos coeficientes deben calcular? aunque me gustaría que ustedes calculasen este número prefiero decirles y que cada uno después intente responder esa pregunta. Dado que tenemos $784$ puntos, podríamos calcular $784$ coeficientes. Algo conforme a la información existente. Entonces para los coeficientes de la serie Seno y Coseno podría calcular $392$. En la práctica, ¿cuántos voy a necesitar? Esta es la pregunta que quiero que resuelvan a la vez que deben hacer una optimización de la forma:\n",
    "$$\\hat{y}_j=\\frac{1}{1+e^{-\\mathbb{A}_{fourier}^{(j)}\\cdot\\bar{\\mathbb{X}}_{opt}}},$$\n",
    "siendo $\\bar{\\mathbb{X}}_{opt}$ los pesos que optimizan la predicción de nuestro algoritmo para los $n_{fourier}$ componentes de Fourier que utilizo. Ustedes se preguntarán, y ¿por qué podemos hacer esto? la respuesta está, para quienes quieran leer un poco más, en las redes neuronales convolucionadas. Deben realizar las mismas gráficas del análisis anterior con PCA.\n",
    "\n",
    "Recomendación, utilice las funciones `SFourier` e `int_cuadrada_trapecio` que escribimos en clase para calcular los coeficientes de Fourier debido a que es una partición simétrica del intervalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_cuadrada_trapecio(f,a,b):\n",
    "    N = len(f)-1\n",
    "    assert a<b\n",
    "    Delta = (b-a)/N\n",
    "    x_i = np.linspace(a,b,N+1)\n",
    "    # f tiene que ser una función vectorizada\n",
    "    f_xi = f\n",
    "    # estimación media excluye el último punto\n",
    "    area = (0.5*f_xi[0]+np.sum(f_xi[1:-1])+0.5*f_xi[-1])*Delta\n",
    "    return area\n",
    "def SFourier(y,T,kMax=50):\n",
    "    # y tiene un numero determinado de datos\n",
    "    N = len(y)\n",
    "    t = np.linspace(0,T,N)\n",
    "    a = []\n",
    "    b = []\n",
    "    for k in range(kMax+1):\n",
    "        wk = 2*np.pi*k/T\n",
    "        # Usando la función de integración de trapecio con intervalos uniformes\n",
    "        ak = (2/T)*int_cuadrada_trapecio(y*np.cos(wk*t),0,T)\n",
    "        bk = (2/T)*int_cuadrada_trapecio(y*np.sin(wk*t),0,T)\n",
    "        a.append(ak)\n",
    "        b.append(bk)\n",
    "    return a,b\n",
    "def transformA(M,N=15):\n",
    "    # Escriba aquí la función teniendo en cuenta que si N=15\n",
    "    # usted va a escoger 31 elementos de la serie: 1 del a_0\n",
    "    # + 15 primeros de la serie coseno y 15 primeros de la\n",
    "    # serie seno\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforme A en A_fourier con n_fourier coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimice y encuentre Xhat_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¡Encuentre las etiquetas y grafique!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¡Espero se diviertan! Buena suerte a tod@s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fisi2028",
   "language": "python",
   "name": "fisi2028"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
